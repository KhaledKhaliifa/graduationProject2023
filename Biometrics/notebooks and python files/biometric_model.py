# -*- coding: utf-8 -*-
"""Biometric_Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hFIOHwOJxt0W9zC7AxPDnfQYSJns52h5

# Model Training
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
import warnings
import pickle

warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/MyDrive/Projects/GP Project/biometric/csv_files/Uniform_users.csv")

df.head()

df.drop(columns=df.columns[0], axis=1, inplace = True)

df.shape

df.head()

x = df.loc[:, df.columns != 'label']
y = df.label

y.head()

# x = x.apply(lambda iterator: ((iterator.max() - iterator)/(iterator.max() - iterator.min())).round(2))
# x.head()

"""## Training"""

X_train, X_both, y_train, y_both = train_test_split(x, y, test_size = 0.2, random_state=3)
X_test, X_valid, y_test, y_valid = train_test_split(X_both, y_both, test_size = 0.5, random_state=3)

X_train.shape

X_test.shape

"""### KNN"""

knn = KNeighborsClassifier()
k_range = list(range(1, 31))
param_grid = dict(n_neighbors=k_range)
  
# defining parameter range
knn_n = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)
  
# fitting the model for grid search
grid_search=knn_n.fit(X_train, y_train)

print(grid_search.best_params_)

knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train, y_train)
yy_pred = knn.predict(X_valid)
print(confusion_matrix(y_valid, yy_pred))
print(classification_report(y_valid, yy_pred))

"""### Logistic"""

LR = LogisticRegression()
LRparam_grid = {
    'C': [0.01, 0.1, 1, 10, 100, 1000],
    'penalty': ['none','l1', 'l2'],
    'solver': ['lbfgs', 'liblinear']
}
LR_search = GridSearchCV(LR, param_grid = LRparam_grid, refit = True, verbose = 1, cv=10)

# fitting the model for grid search 
LR_search.fit(X_train , y_train)

paralist = []
paralist = list(LR_search.best_params_.values())

lr = LogisticRegression(C= paralist[0] , penalty= paralist[1], solver= paralist[2])
lr.fit(X_train, y_train)

yy_pred1 = lr.predict(X_valid)
print(confusion_matrix(y_valid, yy_pred1))
print(classification_report(y_valid, yy_pred1))

"""### Random Forset"""

rf = RandomForestClassifier(random_state=3)
rf.fit(X_train, y_train)
yy_pred2 = rf.predict(X_valid)
print(confusion_matrix(y_valid, yy_pred2))
print(classification_report(y_valid, yy_pred2))

"""### Decision Tree"""

dtree = DecisionTreeClassifier(random_state=3)
dtreeparam_grid = {
    'max_depth': np.arange(1,17),
    'max_features': np.arange(1,12),
    'random_state': [3]
}
dtree_search = GridSearchCV(dtree, param_grid = dtreeparam_grid, refit = True, verbose = 1, cv=10)
dtree_search.fit(X_train , y_train)

paralist = []
paralist = list(dtree_search.best_params_.values())

dtree = DecisionTreeClassifier(criterion = "entropy", max_depth= paralist[0], max_features =paralist[1], random_state=3)
dtree.fit(X_train, y_train)
yy_pred3 = dtree.predict(X_valid)
print(confusion_matrix(y_valid, yy_pred3))
print(classification_report(y_valid, yy_pred3))

from sklearn.tree import export_graphviz
from six import StringIO
from IPython.display import Image
import pydotplus
dot_data = StringIO()
export_graphviz(dtree, out_file = dot_data, rounded = True, filled = True, special_characters = True)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png("dtree.png")
Image(graph.create_png())

"""### Support Vector Machine"""

svc = SVC()
svcparam_grid = {
    'kernel': ['rbf','sigmoid'],
    'degree': np.arange(1,3),
    'random_state':[3],
    'C': np.arange(0,2),
    'gamma':['scale', 'auto']
}
svc_search = GridSearchCV(svc, param_grid = svcparam_grid, refit = True, verbose = 1, cv=10)
svc_search.fit(X_train , y_train)

paralist = []
paralist = list(svc_search.best_params_.values())

svc = SVC(C =paralist[0], degree= paralist[1], gamma=paralist[2], kernel = paralist[3], random_state=3)
svc.fit(X_train, y_train)
yy_pred4 = svc.predict(X_valid)
print(confusion_matrix(y_valid, yy_pred4))
print(classification_report(y_valid, yy_pred4))

"""### loading and saving the models"""

# pickle.dump(rf, open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/random_forest_nl.pickle', "wb"))
# pickle.dump(knn, open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/knn_nl.pickle', "wb"))
# pickle.dump(dtree, open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/dtree_nl.pickle', "wb"))
# pickle.dump(svc, open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/svm_nl.pickle', "wb"))
# pickle.dump(lr, open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/lr_nl.pickle', "wb"))

rf = pickle.load(open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/random_forest.pickle', "rb"))
knn = pickle.load(open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/knn.pickle', "rb"))
dtree = pickle.load(open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/dtree.pickle', "rb"))
svc = pickle.load(open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/svm.pickle', "rb"))
lr = pickle.load(open('/content/drive/MyDrive/Projects/GP Project/biometric/Models/lr.pickle', "rb"))

"""# Testing

"""

y_pred1 = knn.predict(X_test)
print(confusion_matrix(y_test, y_pred1))
print(classification_report(y_test, y_pred1))

f1_score(y_test, y_pred1, average='weighted')

y_pred5 = rf.predict(X_test)
print(confusion_matrix(y_test, y_pred5))
print(classification_report(y_test, y_pred5))

f1_score(y_test, y_pred5, average='weighted')

y_pred2 = lr.predict(X_test)
print(confusion_matrix(y_test, y_pred2))
print(classification_report(y_test, y_pred2))

f1_score(y_test, y_pred2, average='weighted')

y_pred3 = dtree.predict(X_test)
print(confusion_matrix(y_test, y_pred3))
print(classification_report(y_test, y_pred3))

f1_score(y_test, y_pred3, average='weighted')

y_pred4 = svc.predict(X_test)
print(confusion_matrix(y_test, y_pred4))
print(classification_report(y_test, y_pred4))

f1_score(y_test, y_pred4, average='weighted')

mat1 = confusion_matrix(y_test, y_pred1)
mat5 = confusion_matrix(y_test, y_pred5)
mat2 = confusion_matrix(y_test, y_pred2)
mat3 = confusion_matrix(y_test, y_pred3)
mat4 = confusion_matrix(y_test, y_pred4)

"""# Plotting"""

#making a dictionary with each word in our dataset as a key
my_dic = {'User1': 1, 'User2': 2, 'User3': 3, 'User4': 4, 'User5': 5}

#making a list of the dataset words
dic = list(my_dic)
outputss = [y_pred1,y_pred5,y_pred2,y_pred3,y_pred4]
my_titles = ["KNN","Random Forest","Logistic","Decision Tree","SVM"]

matrix = [mat1, mat5, mat2, mat3, mat4]
pred_values = []
#getting the predicted values for each user for all models
for m in  matrix:
  for i in range(5):
    pred_values.append(m[i][i])
print(pred_values)

# function to add value labels
def addlabels(x,y):
    for i in range(len(x)):
        plt.text(i, y[i]/2, round(y[i],2), ha = 'center')

import matplotlib.pyplot as plt

# Define the list of users and the list of predicted values
start = 0  
end = 5  

# plot all models predicted values in respect to the actual values
for i in range(5):  # loop through each machine learning model
  plt.figure(figsize=(5,6))  
  
  # extract sublist of predicted values for current machine learning model
  predicted_values = pred_values[start:end]  
  start += 5  
  end += 5 
  
  # Define the list of support values (i.e., actual values)
  actual_values = [38, 43, 54, 51, 54]
  
  # Create a bar plot with predicted and actual values
  X_axis = np.arange(5)
  # Predicted values are plotted with an offset of -0.2 on x-axis
  plt.bar(X_axis - 0.1, predicted_values, 0.2, label = 'Predicted', color="orange")
  # Actual values are plotted with an offset of +0.2 on x-axis
  plt.bar(X_axis + 0.1, actual_values, 0.2, label = 'Actual', color="green")

  plt.xticks(X_axis, dic)  
  plt.xlabel('Users')  
  plt.ylabel('Count') 
  plt.title(f'Actual and Predicted values for Users using {my_titles[i]}') 
  plt.legend()  
  plt.show()

#plotting the f1-score comparison
x = []
my_titles = ["KNN","Random Forest","Decision Tree","SVM","Logistic"]
for i in range(len(outputss)):
  x.append(f1_score(y_test, outputss[i], average='weighted'))

x.sort(reverse=True)
plt.figure(figsize=(7,4)) 
plt.title("F1 Score Comparison")
plt.bar(my_titles,x,0.3,color = "#f5c49a")
addlabels(my_titles,x)
plt.xlabel("Model Name")
plt.ylabel("F1 Score")

#ploting heatmap 
for i in range(len(outputss)):
  df = pd.DataFrame(confusion_matrix(y_test, outputss[i]))
  df = df.rename(columns=lambda x: str(dic[x]))
  df = df.rename(index=lambda x: str(dic[x]))
  plt.figure()
  plt.title(my_titles[i])
  sns.heatmap(df,cmap=sns.cubehelix_palette(as_cmap=True))
  plt.show()









